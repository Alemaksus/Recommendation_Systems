{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMBdGcvjC4Ji"
   },
   "source": [
    "# Вебинар 6. Двухуровневые модели рекомендаций\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Jgaacz0C4Jl"
   },
   "source": [
    "Код для src, utils, metrics вы можете скачать из [этого](https://github.com/geangohn/recsys-tutorial) github репозитория"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5Aur99NsC4Jm",
    "outputId": "9b9a338b-a52f-4253-9694-ac431b62eefc"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bd30f73f9457>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# Написанные нами функции\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_at_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprefilter_items\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecommenders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMainRecommender\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit import als\n",
    "\n",
    "# Модель второго уровня\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "# Написанные нами функции\n",
    "from metrics import precision_at_k, recall_at_k\n",
    "from utils import prefilter_items\n",
    "from recommenders import MainRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_data(df_data, name_df):\n",
    "    print(name_df)\n",
    "    print(f\"Shape: {df_data.shape} Users: {df_data[USER_COL].nunique()} Items: {df_data[ITEM_COL].nunique()}\")\n",
    "    \n",
    "def make_recommendations(df_result, recommend_model, N_PREDICT=50, USER_COL='user_id'):\n",
    "    return df_result[USER_COL].apply(lambda x: recommend_model(x, N=N_PREDICT))\n",
    "\n",
    "def calc_recall(df_data, top_k, ACTUAL_COL='actual'):\n",
    "    for col_name in df_data.columns[2:]:\n",
    "        yield col_name, df_data.apply(lambda row: recall_at_k(row[col_name], row[ACTUAL_COL], k=top_k), axis=1).mean()\n",
    "        \n",
    "def calc_precision(df_data, top_k, ACTUAL_COL='actual'):\n",
    "    for col_name in df_data.columns[2:]:\n",
    "        yield col_name, df_data.apply(lambda row: precision_at_k(row[col_name], row[ACTUAL_COL], k=top_k), axis=1).mean()\n",
    "        \n",
    "def rerank(user_id, df, USER_COL='user_id', proba_col_name='proba_item_purchase', N=5):\n",
    "    return df[df[USER_COL]==user_id].sort_values(proba_col_name, ascending=False).head(N).item_id.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vso_erSdC4Jo",
    "outputId": "da20dbf1-3086-4fd6-ac92-f7653d7f9f71"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('retail_train.csv')\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "\n",
    "ITEM_COL = 'item_id'\n",
    "USER_COL = 'user_id'\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "\n",
    "# Важна схема обучения и валидации!\n",
    "# -- давние покупки -- | -- 6 недель -- | -- 3 недель -- \n",
    "# подобрать размер 2-ого датасета (6 недель) --> learning curve (зависимость метрики recall@k от размера датасета)\n",
    "VAL_MATCHER_WEEKS = 6\n",
    "VAL_RANKER_WEEKS = 3\n",
    "\n",
    "# берем данные для тренировки matching модели\n",
    "data_train_matcher = data[data['week_no'] < data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)]\n",
    "\n",
    "# берем данные для валидации matching модели\n",
    "data_val_matcher = data[(data['week_no'] >= data['week_no'].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)) &\n",
    "                      (data['week_no'] < data['week_no'].max() - (VAL_RANKER_WEEKS))]\n",
    "\n",
    "\n",
    "# берем данные для тренировки ranking модели\n",
    "data_train_ranker = data_val_matcher.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "\n",
    "# берем данные для теста ranking, matching модели\n",
    "data_val_ranker = data[data['week_no'] >= data['week_no'].max() - VAL_RANKER_WEEKS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats_data(df_data, name_df):\n",
    "    print(name_df)\n",
    "    print(f\"Shape: {df_data.shape} Users: {df_data[USER_COL].nunique()} Items: {df_data[ITEM_COL].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_matcher\n",
      "Shape: (2108779, 12) Users: 2498 Items: 83685\n",
      "val_matcher\n",
      "Shape: (169711, 12) Users: 2154 Items: 27649\n",
      "train_ranker\n",
      "Shape: (169711, 12) Users: 2154 Items: 27649\n",
      "val_ranker\n",
      "Shape: (118314, 12) Users: 2042 Items: 24329\n"
     ]
    }
   ],
   "source": [
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_matcher.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zcnV3l4XC4Jp",
    "outputId": "d58f889c-0671-4bb9-b2b6-2dc2e8c24fce"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prefilter_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-1c5ff868651a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn_items_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train_matcher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata_train_matcher\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefilter_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train_matcher\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtake_n_popular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mn_items_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_train_matcher\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prefilter_items' is not defined"
     ]
    }
   ],
   "source": [
    "n_items_before = data_train_matcher['item_id'].nunique()\n",
    "\n",
    "data_train_matcher = prefilter_items(data_train_matcher, item_features=item_features, take_n_popular=5000)\n",
    "\n",
    "n_items_after = data_train_matcher['item_id'].nunique()\n",
    "print('Decreased # items from {} to {}'.format(n_items_before, n_items_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем общих пользователей\n",
    "common_users = list(set(data_train_matcher.user_id.values)&(set(data_val_matcher.user_id.values))&set(data_val_ranker.user_id.values))\n",
    "\n",
    "data_train_matcher = data_train_matcher[data_train_matcher.user_id.isin(common_users)]\n",
    "data_val_matcher = data_val_matcher[data_val_matcher.user_id.isin(common_users)]\n",
    "data_train_ranker = data_train_ranker[data_train_ranker.user_id.isin(common_users)]\n",
    "data_val_ranker = data_val_ranker[data_val_ranker.user_id.isin(common_users)]\n",
    "\n",
    "print_stats_data(data_train_matcher,'train_matcher')\n",
    "print_stats_data(data_val_matcher,'val_matcher')\n",
    "print_stats_data(data_train_ranker,'train_ranker')\n",
    "print_stats_data(data_val_ranker,'val_ranker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "729d4287bb794971802d9da5e141f10a",
      "32375ef613474af6a0fcadb9255eb835"
     ]
    },
    "id": "zgYXRQ0lC4Jq",
    "outputId": "d9ea41ae-3b4d-41b4-fc46-90868ebb9894"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "729d4287bb794971802d9da5e141f10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32375ef613474af6a0fcadb9255eb835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5001.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "recommender = MainRecommender(data_train_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB9JX5swC4Jr",
    "outputId": "af05502b-1fb9-42b6-919c-b915ac3a0106"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[899624, 1106523, 1044078, 871756, 844179]"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_als_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PNVa6jWLC4Jr",
    "outputId": "c69395e4-8171-41f1-c0c4-067b582f26e0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[948640, 918046, 847962, 907099, 873980]"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_own_recommendations(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0NoB_lSJC4Js",
    "outputId": "9f91a42c-08bf-4037-fca1-54db5a5cafee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1046545, 1044078, 1044078, 1078652, 1018809]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_items_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdQO5CWKC4Js",
    "outputId": "08936fbf-715f-412a-9fbe-065816bb6a90"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1101502, 979674, 10457044, 974265, 959455]"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommender.get_similar_users_recommendation(2375, N=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bqs9Sw_YC4Jt"
   },
   "source": [
    "### Задание 1\n",
    "\n",
    "A) Попробуйте различные варианты генерации кандидатов. Какие из них дают наибольший recall@k ?\n",
    "- Пока пробуем отобрать 50 кандидатов (k=50)\n",
    "- Качество измеряем на data_val_lvl_1: следующие 6 недель после трейна\n",
    "\n",
    "Дают ли own recommendtions + top-popular лучший recall?  \n",
    "\n",
    "B)* Как зависит recall@k от k? Постройте для одной схемы генерации кандидатов эту зависимость для k = {20, 50, 100, 200, 500}  \n",
    "C)* Исходя из прошлого вопроса, как вы думаете, какое значение k является наиболее разумным?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "frt2RzDWC4Jt",
    "outputId": "7c594abf-4a34-406b-9897-8bfbddf69a93"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[853529, 865456, 867607, 872137, 874905, 87524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>[15830248, 838136, 839656, 861272, 866211, 870...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id                                             actual\n",
       "0        1  [853529, 865456, 867607, 872137, 874905, 87524...\n",
       "1        2  [15830248, 838136, 839656, 861272, 866211, 870..."
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ACTUAL_COL = 'actual'\n",
    "result_eval_matcher = data_val_matcher.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_eval_matcher.columns=[USER_COL, ACTUAL_COL]\n",
    "result_eval_matcher.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xM5W4mU4C4Jt"
   },
   "outputs": [],
   "source": [
    "# your_code\n",
    "\n",
    "models = {'own_rec': recommender.get_own_recommendations, \n",
    "          'sim_item_rec': recommender.get_similar_items_recommendation, \n",
    "          'als_rec': recommender.get_als_recommendations, \n",
    "          'sim_user_rec': recommender.get_similar_users_recommendation}\n",
    "\n",
    "for column_name, model in models.items():\n",
    "    result_eval_matcher[column_name] = make_recommendations(result_eval_matcher, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_matcher.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOPK_RECALL = 50\n",
    "sorted(calc_recall(result_eval_matcher, TOPK_RECALL), key=lambda x: x[1],reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для ситуации, когда отбирается 50 кандидатов, наибольший recall@k показывает модель own recommendtions + top-popularb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_list = [20, 50, 100, 200, 500]\n",
    "\n",
    "for k in k_list:\n",
    "    result_eval_matcher = data_val_matcher.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "    result_eval_matcher.columns=[USER_COL, ACTUAL_COL]\n",
    "    \n",
    "    for column_name, model in models.items():\n",
    "        result_eval_matcher[column_name] = make_recommendations(result_eval_matcher, model, N_PREDICT=k)\n",
    "        \n",
    "    print(f'{k} кандидатов: {sorted(calc_recall(result_eval_matcher, k), key=lambda x: x[1],reverse=True)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То есть при увеличении коэффициента метрика recall@k также будет расти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bAHJu3Z5C4Ju"
   },
   "source": [
    "### Задание 2.\n",
    "\n",
    "Обучите модель 2-ого уровня, при этом:\n",
    "    - Добавьте минимум по 2 фичи для юзера, товара и пары юзер-товар\n",
    "    - Измерьте отдельно precision@5 модели 1-ого уровня и двухуровневой модели на data_val_lvl_2\n",
    "    - Вырос ли precision@5 при использовании двухуровневой модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZQcrch7C4Ju"
   },
   "outputs": [],
   "source": [
    "# взяли пользователей из трейна для ранжирования\n",
    "N_PREDICT = 100\n",
    "\n",
    "df_match_candidates = pd.DataFrame(data_train_ranker[USER_COL].unique())\n",
    "df_match_candidates.columns = [USER_COL]\n",
    "\n",
    "df_match_candidates['candidates'] = make_recommendations(df_match_candidates, recommender.get_own_recommendations, \n",
    "                                                         N_PREDICT=N_PREDICT)\n",
    "\n",
    "df_items = df_match_candidates.apply(lambda x: pd.Series(x['candidates']), axis=1).stack().reset_index(level=1, drop=True)\n",
    "df_items.name = 'item_id'\n",
    "df_match_candidates = df_match_candidates.drop('candidates', axis=1).join(df_items)\n",
    "\n",
    "df_match_candidates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = data_train_ranker[[USER_COL, ITEM_COL]].copy()\n",
    "df_ranker_train['target'] = 1  # тут только покупки \n",
    "\n",
    "df_ranker_train = df_match_candidates.merge(df_ranker_train, on=[USER_COL, ITEM_COL], how='left')\n",
    "\n",
    "# чистим дубликаты\n",
    "df_ranker_train = df_ranker_train.drop_duplicates(subset=[USER_COL, ITEM_COL])\n",
    "\n",
    "df_ranker_train['target'].fillna(0, inplace= True)\n",
    "\n",
    "df_ranker_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_train = df_ranker_train.merge(item_features, on='item_id', how='left')\n",
    "df_ranker_train = df_ranker_train.merge(user_features, on='user_id', how='left')\n",
    "\n",
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средний чек для пользователя\n",
    "users_sales = data_train_ranker.groupby(USER_COL)[['sales_value', 'quantity']].sum().reset_index()\n",
    "users_sales['avg_transaction'] = users_sales['sales_value'] / users_sales['quantity']\n",
    "df_ranker_train = df_ranker_train.merge(users_sales[['user_id', 'avg_transaction']], on='user_id', how='left')\n",
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Добавим параметр категории к исходному обучающему датасету для создания новых фичей\n",
    "data_department = data_train_ranker.merge(item_features[['item_id', 'department']], on='item_id', how='inner')\n",
    "data_department.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество покупок в каждой категории и среднее сумма покупки в каждой категории\n",
    "users_sales_department = data_department.groupby([USER_COL, 'department'])\\\n",
    "                        [['sales_value', 'quantity']].sum().reset_index()\n",
    "users_sales_department.rename(columns={'quantity': 'n_sold_category'}, inplace=True)\n",
    "users_sales_department['avg_transaction_category'] = users_sales_department['sales_value']\\\n",
    "                                                    /users_sales_department['n_sold_category']\n",
    "users_sales_department.drop(columns=['sales_value'], inplace=True)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(\n",
    "    users_sales_department, on=[USER_COL, 'department'], how='left')\n",
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Средняя сумма покупки в категории\n",
    "department_sales = data_department.groupby('department')['sales_value'].mean().reset_index()\n",
    "department_sales.rename(columns={'sales_value': 'mean_sales_value_category'}, inplace=True)\n",
    "department_sales.tail(2)\n",
    "\n",
    "n_weeks = data_department['week_no'].max() - data_department['week_no'].min() + 1\n",
    "\n",
    "# Количество покупок юзером конкретной категории в неделю\n",
    "users_department = data_department.groupby([USER_COL, 'department'])['quantity'].sum().reset_index()\n",
    "users_department['quantity'] /= n_weeks\n",
    "users_department.rename(columns={'quantity': 'n_sold_category_user_week'}, inplace=True)\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(department_sales, on='department', how='left')\n",
    "df_ranker_train = df_ranker_train.merge(users_department, on=[USER_COL, 'department'], how='left')\n",
    "df_ranker_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Цена\n",
    "items_sales = data_department.groupby(ITEM_COL)[['sales_value', 'quantity']].sum().reset_index()\n",
    "items_sales['price'] = items_sales['sales_value'] / items_sales['quantity']\n",
    "items_sales['price'].fillna(0, inplace=True)\n",
    "\n",
    "# Количество покупок в неделю\n",
    "items_sales['quantity_per_week'] = items_sales['quantity'] / n_weeks\n",
    "\n",
    "\n",
    "df_ranker_train = df_ranker_train.merge(items_sales[[ITEM_COL,'price', 'quantity_per_week']],\n",
    "                                        on=ITEM_COL, how='left')\n",
    "\n",
    "df_ranker_train['Missing price'] = 0\n",
    "df_ranker_train.loc[df_ranker_train['price'].isna(), 'Missing price'] = 1\n",
    "df_ranker_train['price'].fillna(0, inplace=True)\n",
    "\n",
    "df_ranker_train['Missing quantity per week'] = 0\n",
    "df_ranker_train.loc[df_ranker_train['quantity_per_week'].isna(), 'Missing quantity per week'] = 1\n",
    "df_ranker_train['quantity_per_week'].fillna(0, inplace=True)\n",
    "\n",
    "df_ranker_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_ranker_train.drop('target', axis=1)\n",
    "y_train = df_ranker_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = X_train.columns[2:15].tolist() + X_train.columns[-2:].tolist()\n",
    "\n",
    "\n",
    "for column in cat_feats:\n",
    "    X_train[column].fillna(0, inplace=True)\n",
    "    \n",
    "X_train[cat_feats] = X_train[cat_feats].astype('category')\n",
    "\n",
    "cat_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "cb = CatBoostClassifier(learning_rate=0.1,\n",
    "                        max_depth=12,\n",
    "                        n_estimators=700,\n",
    "                        random_state=42, \n",
    "                        cat_features=cat_feats, \n",
    "                        silent=True)\n",
    "\n",
    "cb.fit(X_train, y_train)\n",
    "\n",
    "train_preds = cb.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ranker_predict = df_ranker_train.copy()\n",
    "df_ranker_predict['proba_item_purchase'] = train_preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_PREDICT = 100\n",
    "TOPK_PRECISION = 5\n",
    "\n",
    "result_eval_ranker = data_val_ranker.groupby(USER_COL)[ITEM_COL].unique().reset_index()\n",
    "result_eval_ranker.columns=[USER_COL, ACTUAL_COL]\n",
    "result_eval_ranker['own_rec'] = make_recommendations(result_eval_ranker, \n",
    "                                                     recommender.get_own_recommendations, N_PREDICT=N_PREDICT)\n",
    "\n",
    "sorted(calc_precision(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_eval_ranker['reranked_own_rec'] = result_eval_ranker[USER_COL].\\\n",
    "                                            apply(lambda user_id: rerank(user_id, df_ranker_predict))\n",
    "print(*sorted(calc_precision(result_eval_ranker, TOPK_PRECISION), key=lambda x: x[1], reverse=True), sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили, что модель второго уровня оказалось значительно лучше, чем отбор товаров на основе модели первого уровня без дополнительного ранжирования."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_webinar_6.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
