{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1XjeTzsz7_x"
   },
   "source": [
    "## Теоретическая часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FISrRJh6z7_4"
   },
   "source": [
    "\n",
    "1. Ответьте на вопросы:  \n",
    "В чем принципиальное отличие гибридных рекомендательных систем от коллаборативной филтьтрации?  \n",
    "Приведите 2-3 примера задач, в которых необходимо использовать гибридные системы  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответы\n",
    "\n",
    "1. Коллаборативная фильтрация может быть частью гибридной РС, которая может включать в себя кроме этого вида фильтрации, ещё и контентную фильтрацию, либо какую либу иную форму фильтрации. Кроме того, коллаборативная требует наличия исторических данных о товаре или клиенте, а гибридная может этого избежать, если изначально будет рассматривать контентный анализ. Таким образом можно избавиться от проблемы \"хоролдного старта\"\n",
    "\n",
    "2. Netflix - гибрид. Amazon в начале своей деятельности - это популяризация коллаборативной фильтрации, которая здесб дыла полностью испробована и давала неплохие результаты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E64QMf0Oz7_6"
   },
   "source": [
    "2.  Прочитайте статью про поиск на hh.ru https://habr.com/ru/company/hh/blog/347276/\n",
    "Нам интересна именно рекомендательная система, раздел \"Производительность системы\" можно пропустить\n",
    "Какие основные отличия предложенной системы от тех подходов, которые мы разбирали на семинарах? Какие проблемы могут возникнуть при выводе такой модели в продакшен?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ\n",
    "\n",
    "1. гибридную систему где сначало идет контентный фильтр для признаков по вакансиям с помощью библиотеки Lucene. \n",
    "Затем расчет признаков по методу пар (paitwise)\n",
    "Потом фильрующая модель logit (с удлучшением и отладкой модели за счте подкачки offline метрик).\n",
    "Потом ранжирующая модель (XGBoost) \n",
    "Потом выгрузка результатов клиенту и A/B-тесты\n",
    "Всё это зацикливается и как-то должно работать.\n",
    "\n",
    "Проблемы две: вычислительные мощности и ручное измерение offline-метрик. С обеими проблемами нужно явно вести борьбу в данной общей гибридной модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNE5pEkJz7_6"
   },
   "source": [
    "3. На вебинаре мы рассматривали модель LightFM (https://making.lyst.com/lightfm/docs/lightfm.html). В работе Data Scientist'а важную часть занимает research - исследование существующих архитектур и разбор научных статей, в которых они описываются. Вам предлагается изчуть оригинальную статью про LightFM https://arxiv.org/pdf/1507.08439.pdf и ответить на следующие вопросы:  \n",
    "1) Какой датасет используют авторы?  \n",
    "2) Что используют в качестве признаков?  \n",
    "3) С какими моделями сравнивают LightFM? Опишите их основные идеи кратко  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ответ:\n",
    "    \n",
    "    1) Огромный каталог модной одежды на 8 млн позиций (+ десятки тысяч позиций обновляются каждый день).\n",
    "    Разбит на 2 датасета (DS): один охватывают диапазон данных плотного взаимодействия юзера с товарами, где можно ожидать, что модели матричной факторизации (MF) будут работать хорошо (название DS - MovieLens), и разреженных данных, где контентые модели (CB), будут работать скорее всего лучше (DS - CrossValidated). \n",
    "    \n",
    "    2) В DS MovieLens: юзеры, товары, взаимодействия, уникальные теги.\n",
    "    В DS CrossValidated: юзеры + метаданные \"Обо мне\", вопросы + уникальные теги, ответы и комментарии.\n",
    "    \n",
    "    3) Для сравнения с LightFM автором брались следующие можели: \n",
    "    \n",
    "    1. MF: традиционная модель матричной факторизации со смещением пользователя и элемента и сигмовидной функцией связи [8].\n",
    "\n",
    "2. LSI-LR: модель на основе контента. Чтобы оценить его, я сначала вывожу скрытые темы из матрицы элементов-функций с помощью латентной семантической индексации и представляю элементы как линейные комбинации скрытых тем. Затем я подбираю отдельную модель логистической регрессии (LR) для каждого пользователя в пространстве смешения тем. В отличие от модели LightFM, которая использует совместные данные для создания своего скрытого представления, LSI-LR основана исключительно на факторизации матрицы контента. Поэтому это должно быть полезно для выделения преимуществ использования совместной информации для построения вложений функций.\n",
    "\n",
    "3. LSI-UP: гибридная модель, которая представляет профили пользователей (UP) как линейные комбинации векторов содержимого элементов, а затем применяет LSI к результирующей матрице для получения скрытых представлений пользователей и элементов. Я оцениваю эту модель, сначала создавая матрицу характеристик пользователя: каждая строка представляет пользователя и задается суммой векторов характеристик контента, представляющих элементы, с которыми пользователь положительно взаимодействовал. Затем я применяю усеченный SVD к нормализованной матрице, чтобы получить скрытые векторы пользователей и признаков; Скрытые векторы элементов получаются путем их проецирования на пространство скрытых признаков. Таким образом, оценка рекомендаций для пары «пользователь-элемент» является внутренним продуктом их скрытых представлений.\n",
    "\n",
    "4. LightFM (теги): модель LightFM, использующая только функции тегов.\n",
    "\n",
    "5. LightFM (теги + идентификаторы): модель LightFM, использующая функции тегов и индикаторов элементов.\n",
    "\n",
    "6. LightFM (теги + информация): модель LightFM, использующая как предметные, так и пользовательские функции. Пользовательские функции доступны только для набора данных CrossValidated. Я создаю их, преобразовывая разделы «Обо мне» профилей пользователей в набор слов. Сначала я удаляю из них все HTML-теги и неалфавитные символы, затем преобразую полученную строку в нижний регистр и размечаю пробелами.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n19OhGm_z7_7"
   },
   "source": [
    "## Практическая часть\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9a2DNsNKz7_8",
    "outputId": "8e2537c9-16c8-4ebc-b321-f4bfa253b079"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightfm\\_lightfm_fast.py:10: UserWarning: LightFM was compiled without OpenMP support. Only a single thread will be used.\n",
      "  \"LightFM was compiled without OpenMP support. \"\n"
     ]
    }
   ],
   "source": [
    "import lightfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nHTovEfPz7_-"
   },
   "outputs": [],
   "source": [
    "# import data\n",
    "# utils functions like in webinar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZnN3kRlz7__"
   },
   "source": [
    "### 1. Модуль SRC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OKLq6JBxz8AA"
   },
   "source": [
    "На вебинаре было рассказано про модуль src. Он приложен в материалах. Скачайте его, изучите структуру, импортируйте функции"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5PtkoIlz8AB"
   },
   "source": [
    "### 2. Работа с признаками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U29uOLDNz8AC"
   },
   "source": [
    "У нас есть внешние данные. Что с ними не так? Чего не хватает?  \n",
    "\n",
    "Проведите исследование внешних данных и составьте какие-нибудь содержательные выводы.  \n",
    "Формально Вам нужно построить 3+ графиков (scatter plot, hist или что-то иное) и описать, что мы видим (например, товары такой-то категории болле часто покупаются в следующие дни недели или пользователи с большим достатком предпочитают такие-то товары).  \n",
    "Исследуйте те закономерности, которые Вам интересно, чем менее тривиальный вывод получается, тем лучше! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HYWWYQmz8AC"
   },
   "source": [
    "### 3. LightFM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFZVbwN-z8AD"
   },
   "source": [
    "У этого алогритма есть множество параметров (item/user_alpha, loss, no_components).  \n",
    "Проведите эксперименты аналогично дз 3 (подберите гипперпараметры каким удобно способои и постройте графики)  \n",
    "На выходе необходимо получить pr@5 на валидации (последние 3 недели) > 2%  \n",
    "\n",
    "У Вас, скорее всего, возникнет проблема со временем обучения. Почему они возникает?    \n",
    "\n",
    "Попробуйте запустить алгоритм вообще без фичей или используйте только признаки с небольшим числом уникальных категорий. (item_features['commodity_desc'].unique() - 300 уникальных категорий - это очень много)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hLnjWB6Lz8AD"
   },
   "source": [
    "### *Отбор признаков* * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3-DjadOz8AE"
   },
   "source": [
    "Все данные категориальные, при ohe кодировании для товаров признаков становится невероятно много.      \n",
    "Какие стратегии отбора признаков в классическом ML Вы знаете? Применимы ли они тут?  \n",
    "\n",
    "Попробйте какие-нибудь стратегии. Удалось ли улучшить качество?\n",
    "\n",
    " \\* *задание необязательно*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "gry2IYHKz8AE"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8861773fa1c3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodule_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprecision_at_k\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_at_k\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprefilter_items\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Для работы с матрицами\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "\n",
    "# Матричная факторизация\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight, tfidf_weight\n",
    "\n",
    "from lightfm import LightFM\n",
    "from lightfm.evaluation import precision_at_k, recall_at_k\n",
    "\n",
    "# Функции из 1-ого вебинара\n",
    "import os, sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(os.pardir))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "from src.metrics import precision_at_k, recall_at_k\n",
    "from utils import prefilter_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "m8JdZSBnz8AF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>basket_id</th>\n",
       "      <th>day</th>\n",
       "      <th>item_id</th>\n",
       "      <th>quantity</th>\n",
       "      <th>sales_value</th>\n",
       "      <th>store_id</th>\n",
       "      <th>retail_disc</th>\n",
       "      <th>trans_time</th>\n",
       "      <th>week_no</th>\n",
       "      <th>coupon_disc</th>\n",
       "      <th>coupon_match_disc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1004906</td>\n",
       "      <td>1</td>\n",
       "      <td>1.39</td>\n",
       "      <td>364</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2375</td>\n",
       "      <td>26984851472</td>\n",
       "      <td>1</td>\n",
       "      <td>1033142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1631</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    basket_id  day  item_id  quantity  sales_value  store_id  \\\n",
       "0     2375  26984851472    1  1004906         1         1.39       364   \n",
       "1     2375  26984851472    1  1033142         1         0.82       364   \n",
       "\n",
       "   retail_disc  trans_time  week_no  coupon_disc  coupon_match_disc  \n",
       "0         -0.6        1631        1          0.0                0.0  \n",
       "1          0.0        1631        1          0.0                0.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('retail_train.csv')\n",
    "\n",
    "item_features = pd.read_csv('product.csv')\n",
    "user_features = pd.read_csv('hh_demographic.csv')\n",
    "\n",
    "# column processing\n",
    "item_features.columns = [col.lower() for col in item_features.columns]\n",
    "user_features.columns = [col.lower() for col in user_features.columns]\n",
    "\n",
    "item_features.rename(columns={'product_id': 'item_id'}, inplace=True)\n",
    "user_features.rename(columns={'household_key': 'user_id'}, inplace=True)\n",
    "\n",
    "# train test split\n",
    "test_size_weeks = 3\n",
    "\n",
    "data_train = data[data['week_no'] < data['week_no'].max() - test_size_weeks]\n",
    "data_test = data[data['week_no'] >= data['week_no'].max() - test_size_weeks]\n",
    "\n",
    "data_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8kSXv81cz8AF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>department</th>\n",
       "      <th>brand</th>\n",
       "      <th>commodity_desc</th>\n",
       "      <th>sub_commodity_desc</th>\n",
       "      <th>curr_size_of_product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25671</td>\n",
       "      <td>2</td>\n",
       "      <td>GROCERY</td>\n",
       "      <td>National</td>\n",
       "      <td>FRZN ICE</td>\n",
       "      <td>ICE - CRUSHED/CUBED</td>\n",
       "      <td>22 LB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26081</td>\n",
       "      <td>2</td>\n",
       "      <td>MISC. TRANS.</td>\n",
       "      <td>National</td>\n",
       "      <td>NO COMMODITY DESCRIPTION</td>\n",
       "      <td>NO SUBCOMMODITY DESCRIPTION</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id  manufacturer    department     brand            commodity_desc  \\\n",
       "0    25671             2       GROCERY  National                  FRZN ICE   \n",
       "1    26081             2  MISC. TRANS.  National  NO COMMODITY DESCRIPTION   \n",
       "\n",
       "            sub_commodity_desc curr_size_of_product  \n",
       "0          ICE - CRUSHED/CUBED                22 LB  \n",
       "1  NO SUBCOMMODITY DESCRIPTION                       "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_desc</th>\n",
       "      <th>marital_status_code</th>\n",
       "      <th>income_desc</th>\n",
       "      <th>homeowner_desc</th>\n",
       "      <th>hh_comp_desc</th>\n",
       "      <th>household_size_desc</th>\n",
       "      <th>kid_category_desc</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65+</td>\n",
       "      <td>A</td>\n",
       "      <td>35-49K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45-54</td>\n",
       "      <td>A</td>\n",
       "      <td>50-74K</td>\n",
       "      <td>Homeowner</td>\n",
       "      <td>2 Adults No Kids</td>\n",
       "      <td>2</td>\n",
       "      <td>None/Unknown</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age_desc marital_status_code income_desc homeowner_desc      hh_comp_desc  \\\n",
       "0      65+                   A      35-49K      Homeowner  2 Adults No Kids   \n",
       "1    45-54                   A      50-74K      Homeowner  2 Adults No Kids   \n",
       "\n",
       "  household_size_desc kid_category_desc  user_id  \n",
       "0                   2      None/Unknown        1  \n",
       "1                   2      None/Unknown        7  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prefilter_items' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-0dce3a7319fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_users_test_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnunique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata_train_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefilter_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtake_n_popular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdata_test_filtered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprefilter_items\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtake_n_popular\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitem_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prefilter_items' is not defined"
     ]
    }
   ],
   "source": [
    "n_items_train_before = data_train['item_id'].nunique()\n",
    "n_items_test_before = data_test['item_id'].nunique()\n",
    "n_users_train_before = data_train['user_id'].nunique()\n",
    "n_users_test_before = data_test['user_id'].nunique()\n",
    "\n",
    "data_train_filtered = prefilter_items(data_train, take_n_popular=5000, item_features=item_features)\n",
    "data_test_filtered = prefilter_items(data_test, take_n_popular=5000, item_features=item_features)\n",
    "\n",
    "n_items_train_after = data_train_filtered['item_id'].nunique()\n",
    "n_items_test_after = data_test_filtered['item_id'].nunique()\n",
    "n_users_train_after = data_train_filtered['user_id'].nunique()\n",
    "n_users_test_after = data_test_filtered['user_id'].nunique()\n",
    "print('Decreased # items_train from {} to {}'.format(n_items_train_before, n_items_train_after))\n",
    "print('Decreased # items_test from {} to {}'.format(n_items_test_before, n_items_test_after))\n",
    "print('Decreased # users_train from {} to {}'.format(n_users_train_before, n_users_train_after))\n",
    "print('Decreased # users_test from {} to {}'.format(n_users_test_before, n_users_test_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_train_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-349d15a3cf92>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m user_item_matrix = pd.pivot_table(data_train_filtered, \n\u001b[0m\u001b[0;32m      2\u001b[0m                                   \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                   \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'quantity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Можно пробоват ьдругие варианты\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                   \u001b[0maggfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'count'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0mfill_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_train_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "user_item_matrix = pd.pivot_table(data_train_filtered, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробоват ьдругие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "user_item_matrix = user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "\n",
    "# переведем в формат saprse matrix\n",
    "sparse_user_item = csr_matrix(user_item_matrix).tocsr()\n",
    "\n",
    "user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_test_filtered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-94db88357dbe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m test_user_item_matrix = pd.pivot_table(data_test_filtered, \n\u001b[0m\u001b[0;32m      4\u001b[0m                                   \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'item_id'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'quantity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# Можно пробовать другие варианты\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_test_filtered' is not defined"
     ]
    }
   ],
   "source": [
    "data_test = data_test[data_test['item_id'].isin(data_train['item_id'].unique())]\n",
    "\n",
    "test_user_item_matrix = pd.pivot_table(data_test_filtered, \n",
    "                                  index='user_id', columns='item_id', \n",
    "                                  values='quantity', # Можно пробовать другие варианты\n",
    "                                  aggfunc='count', \n",
    "                                  fill_value=0\n",
    "                                 )\n",
    "\n",
    "test_user_item_matrix = test_user_item_matrix.astype(float) # необходимый тип матрицы для implicit\n",
    "test_user_item_matrix.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_item_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-85b7db73fffb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0muserids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mitemids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_item_matrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mmatrix_userids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muserids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmatrix_itemids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitemids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_item_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "userids = user_item_matrix.index.values\n",
    "itemids = user_item_matrix.columns.values\n",
    "\n",
    "matrix_userids = np.arange(len(userids))\n",
    "matrix_itemids = np.arange(len(itemids))\n",
    "\n",
    "id_to_itemid = dict(zip(matrix_itemids, itemids))\n",
    "id_to_userid = dict(zip(matrix_userids, userids))\n",
    "\n",
    "itemid_to_id = dict(zip(itemids, matrix_itemids))\n",
    "userid_to_id = dict(zip(userids, matrix_userids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat = pd.DataFrame(user_item_matrix.index)\n",
    "user_feat = user_feat.merge(user_features, on='user_id', how='left')\n",
    "user_feat.set_index('user_id', inplace=True)\n",
    "user_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_feat = pd.DataFrame(user_item_matrix.columns)\n",
    "item_feat = item_feat.merge(item_features, on='item_id', how='left')\n",
    "item_feat.set_index('item_id', inplace=True)\n",
    "\n",
    "item_feat.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm = pd.get_dummies(user_feat, columns=user_feat.columns.tolist())\n",
    "item_feat_lightfm = pd.get_dummies(item_feat, columns=item_feat.columns.tolist())b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_feat_lightfm.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LightFM(no_components=40,\n",
    "                 loss='bpr',\n",
    "                #loss='warp',\n",
    "                learning_rate=0.05, \n",
    "                item_alpha=0.1,\n",
    "                user_alpha=0.1, \n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4,\n",
    "          verbose=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_precision = precision_at_k(model, sparse_user_item, \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "train_precision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_precision = precision_at_k(model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "\n",
    "test_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import tpe, hp, fmin, STATUS_OK, Trials\n",
    "\n",
    "space = {\n",
    "    'no_components': hp.choice('no_components', [50, 75, 100 ]),\n",
    "    'loss': hp.choice('loss', ['bpr', 'warp']),\n",
    "    'learning_rate': hp.uniform('learning_rate', 0, 0.1),\n",
    "    'item_alpha': hp.uniform('item_alpha', 0, 1),\n",
    "    'user_alpha': hp.uniform('user_alpha', 0, 1)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparametr_tuning(params):\n",
    "    model = LightFM(**params, random_state=42)\n",
    "    \n",
    "    model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4,\n",
    "          verbose=False)\n",
    "    \n",
    "    test_precision = precision_at_k(model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()\n",
    "    \n",
    "    return {'loss': -test_precision, 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = Trials()\n",
    "\n",
    "best = fmin(\n",
    "    fn=hyperparametr_tuning,\n",
    "    space=space,\n",
    "    algo=tpe.suggest,\n",
    "    max_evals=100,\n",
    "    trials=trial\n",
    ")\n",
    "\n",
    "print(f'Best {best}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = LightFM(no_components=50,\n",
    "                loss='warp',\n",
    "                learning_rate=0.03, \n",
    "                item_alpha=0.84,\n",
    "                user_alpha=0.67, \n",
    "                random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.fit((sparse_user_item > 0) * 1,  # user-item matrix из 0 и 1\n",
    "          sample_weight=coo_matrix(user_item_matrix),\n",
    "          user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "          item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "          epochs=15, \n",
    "          num_threads=4,\n",
    "          verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_at_k(best_model, csr_matrix(test_user_item_matrix).tocsr(), \n",
    "                                 user_features=csr_matrix(user_feat_lightfm.values).tocsr(),\n",
    "                                 item_features=csr_matrix(item_feat_lightfm.values).tocsr(),\n",
    "                                 k=5).mean()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
